# Convolutional Neural Network (CNN) w/ Tensorflow (1/2)

### Taehun Kim
---

## Using Image as Input
- PIL (Python Image Library)
- Image is mapped to multi channel 2d-array (= 3d-array)
  - e.g. rgb image : width * height * rgb

```python
import numpy as np
from PIL import Image

ima = Image.open(url) 
npa1 = np.asarray(ima) 
```
- Image is mapped into array directly
---

## Preprocessing : resize
- CNN requires same size of input
- Multiple images having various sizes should be re-sized

### Resizing with python (PIL)
> ![corgi_original](https://gong4py.github.io/images/corgi-1.jpg)
- Example has 465 * 251 size
- Assume that we need 64 * 64 size image

```python
import numpy as np
from PIL import Image

ima = Image.open(url) # this is original image
width = 64
height = 64
ima = ima.resize((width, height)) # this is resized image
npa2 = np.asarray(ima)
```

- Resized image will be 
> ![corgi_resized](https://gong4py.github.io/images/corgi-2.jpg)
---

## Getting Image and Feed it to TF 
- Import tensorflow as tf !
- Create placeholder for x, y; placeholder is a kind of variables having specific size (e.g. n-d array)
- Assume that, 
  - we have 64 * 64 * 3 sized image (input, x)
  - we have two class (1 or 0) output (target, y)
```python
x = tf.placeholder(tf.float32, shape=[None, 64*64*3])
y = tf.placeholder(tf.float32, shape=[None, 2]) # 2 is number of class in label space
```
- Reshape image input for feed
```python
x_ima = tf.reshape(x, [-1, 64, 64, 3])
# [a,b,c,d] = [input number, width, height, channel]
# -1 means same as the input number (dynamic)
# if we can hardly specify the number of input, use -1
```

---
## Creating Convolutional Layer

- Specify the size and output channel of filters
- Add bias if necessary
```python
def weight_variable(shape):
    initial = tf.truncated_normal(shape, stddev=0.1) # small noise for symmetry breaking
    return tf.Variable(initial)

def bias_variable(shape):
    initial = tf.constant(0.1, shape=shape) # prevent dead neuron 
    return tf.Variable(initial)
```
- Assume that we want to have 5 * 5 filters that generate 32 channel output
```python
W_conv = weight_variable([5,5,3,32]) # 3 is channel of input (=rgb 3ch)
b_conv = bias_variable([32])
# W_conv and b_conv should have same output channel size, e.g. 32
```
- Determine the activation function
  - RELU is one of the most preferred one for learning w/ images
```python
tmp_conv = tf.nn.conv2d(x_ima,W_conv, strides=[1,1,1,1], padding='SAME')
tmp_conv = tmp_conv + b_conv
h_conv = tf.nn.relu(tmp_conv)
```
---
## Creating Pooling Layer
- Pooling can reduce the size of input 
- Pooling can prevent the overfitting
- various pooling methods are supported by tf (maxpool, avgpool, w/ argmax, ...)
```python
h_pool = tf.nn.max_pool(h_conv, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')
# be aware of ksize and stride
# if our strides = [1,1,1,1], the output has some overlaps and is not exclusive
```
---
## Creating Fully-Connected (FC) Layer

### Before the FC
- Add sufficient number of convolutional layers and pooling layers
- e.g. C-P-C-P-C-P-FC, C-C-C-C-C-P-FC
```python
# h_pool has 32 * 32 * 32
W_conv2 = weight_variable([5,5,32,64])
b_conv2 = bias_variable([64])

tmp_conv = tf.nn.conv2d(h_pool,W_conv2, strides=[1,1,1,1], padding='SAME')
tmp_conv = tmp_conv + b_conv2
h_conv2 = tf.nn.relu(tmp_conv)

h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')
# ----h_pool2 has 16 * 16 * 64----

W_conv3 = weight_variable([5,5,64,64])
b_conv3 = bias_variable([64])

tmp_conv = tf.nn.conv2d(h_pool2,W_conv3, strides=[1,1,1,1], padding='SAME')
tmp_conv = tmp_conv + b_conv3
h_conv3 = tf.nn.relu(tmp_conv)

h_pool3 = tf.nn.max_pool(h_conv3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')
# ----h_pool3 has 8*8*64----

W_conv4 = weight_variable([5,5,64,64])
b_conv4 = bias_variable([64])

tmp_conv = tf.nn.conv2d(h_pool3,W_conv4, strides=[1,1,1,1], padding='SAME')
tmp_conv = tmp_conv + b_conv4
h_conv4 = tf.nn.relu(tmp_conv)

h_pool4 = tf.nn.max_pool(h_conv4, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')
# ----h_pool4 has 4*4*64----
```
### Now add FC
- Connect the convolution & pooling output
- Assume that we want to have 512 FC output

```python
W_fc = weight_variable([4*4*64, 512])
b_fc = bias_variable([512])

h_pool4_flat = tf.reshape(h_pool4, [-1, 4*4*64])
h_fc = tf.nn.relu(tf.matmul(h_pool4_flat, W_fc)+b_fc)

W_fc2 = weight_variable([512,2])
b_fc2 = bias_variable([2])
# 2 is number of class (1 or 0)

y_conv = tf.matmul(h_fc, W_fc2) + b_fc2
```
---

## Start Learning!
- Before running, finish the graph
- Determine objective function, optimizer, evaluation measure
- tf supports many other built-in objective functions and optimizers 
```python
cross_entropy = tf.reduce_mean(
    tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_conv)
)

train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)

correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
```

- Open session and training
  - Determine batch size (e.g. 100)
  - Determine repetition number of batch training
```python
sess = tf.Session()
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer()) # initialize the graph
    rot = len(x)//100 # 100 is batch size
    for i in range(1000):
        j = i % rot
        x_batch = x[100*j:100*j+100]
        y_batch = y[100*j:100*j+100]
        train_step.run(feed_dict={x:x_batch, y:y_batch})
    
    sess.run(accuracy, feed_dict={x:x, y:y})
```
## TF w/ gpu
- GPU has stronger power for floating-point calculation
  - Large size of calculation by using GPU is much faster than by using CPU
  - tf supports GPU usage

- How to 
  - Prerequisite: nvidia gpu supporting CUDA, tensorflow-gpu
  - Install CUDA and cudnn
  - Install tensorflow-gpu
  - Applying gpu usage
```python
# the graph generation
with tf.device('/gpu:0'):
    ...

# the running
sess = tf.Session(config=tf.configProto(log_device_placement=True))
with tf.Session() as sess:
    ...
```


## Reference
- addition to part.1
- https://stackoverflow.com/questions/384759/pil-and-numpy
- https://www.tensorflow.org/tutorials/using_gpu
- http://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/#axzz4hy8kl6jg
